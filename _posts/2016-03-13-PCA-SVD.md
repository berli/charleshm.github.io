---
published: true
author: Charles
layout: post
title:  "PCA 与 SVD"
date:   2016-03-13 19:35
categories: 机器学习
---

PCA（Principal Component Analysis）是一种常用的数据降维方法，通过线性变换将原始数据变换为一组各维度**线性无关**的表示，以提取数据的主要特征成分。本文着重于理清PCA的数学原理，并给出相应的证明。

#### 数据中的冗余和噪声
我们先举一个例子，假设现在我们拿到这样一组数据，里面有两个属性，既有以“千米/每小时”度量的最大速度特征，也有“英里/小时”的最大速度特征，显然我们一眼就看出这两个特征有一个多余。

![此处输入图片的描述][1]

怎么直观的判断数据是否冗余? 上图从左往右，我们可以发现数据之间的关联性越来越强，也就是说两组数据越来越“相似”，我们用其中一组数据就能预测出另一组数据，这就是数据需要降维的其中一个原因：**冗余**。

另一方面，除了冗余之外，数据中可能还存在噪声，数据记录过程中存在某些不可抗因素的干扰。我们常常用信噪比signal-to-noise ratio (SNR) 来评价一组数据的好坏。

$$SNR = \frac{\delta_{signal}^2}{\delta_{noise}^2}$$

$SNR \gg 1$意味着数据比较纯净，可信度比较高，SNR 较小时，我们常说信号被噪声淹没了。

![此处输入图片的描述][2]

> 换句话说，一组数据中” 信号” 部分的**方差**较大，方差较小的我们可以认定为噪声。

哎呀，我们已经找到PCA 的理论根据了，我们要得到数据中的” 有用” 信息，也就是说我们要找到使数据方差最大的方向。



  [1]: http://7xjbdi.com1.z0.glb.clouddn.com/2016-03-14_164210.png?imageView2/2/w/500
  [2]: http://7xjbdi.com1.z0.glb.clouddn.com/2016-03-14_164741.png?imageView2/2/w/300