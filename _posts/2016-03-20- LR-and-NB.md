---
published: true
author: Charles
layout: post
title:  "Logistic Regression and Naive Bayes"
date:   2016-03-20 9:30
categories: 机器学习
---

#### 数学表示
我们先推导下 Logistic Regression 和 Naive Bayes在数学表达上的相关性[^1].

$$\begin{align*}
P(Y=1|X) & = \frac{P(Y=1)P(X|Y=1)}{P(Y=1)P(X|Y=1)+P(Y=0)P(X|Y=0)}\\
& = \frac{1}{1+\frac{P(Y=0)P(X|Y=0)}{P(Y=1)P(X|Y=1)}}\\
& = \frac{1}{1+\exp(\ln\frac{P(Y=0)P(X|Y=0)}{P(Y=1)P(X|Y=1)})}\\
& = \frac{1}{1+\exp((\ln \frac{1-\pi}{\pi})+\sum_i\ln\frac{P(X_i|Y=0)}{P(X_i|Y=1)})} \tag{1}
\end{align*}$$

我们假设 P(X_i|Y=y_k)服从高斯分布，

$$\begin{align*}
\sum_i\ln\frac{P(X_i|Y=0)}{P(X_i|Y=1)} & = \sum_i\ln\frac{\frac{1}{\sqrt{2\pi\delta_i^2}}\exp(\frac{-(X_i-\mu_{i0})^2}{2\delta_i^2})}{\frac{1}{\sqrt{2\pi\delta_i^2}}\exp(\frac{-(X_i-\mu_{i1})^2}{2\delta_i^2})}\\
& = \sum_i \left( \frac{(X_i-\mu_{i1})^2-(X_i-\mu_{i0})^2}{2\delta_i^2} \right)\\
& = \sum_i \left( \frac{2X_i(\mu_{i0}-\mu_{i1})+\mu_{i1}^2-\mu_{i0}^2}{2\delta_i^2} \right)\\
& = \sum_i \left( \frac{\mu_{i0}-\mu_{i1}}{\delta_i^2} X_i + \frac{\mu_{i1}^2-\mu_{i0}^2}{\delta_i^2} \right) \tag{2}
\end{align*}$$

从而，
$$\begin{align*}
\Rightarrow P(Y=1|X) & = \frac{1}{1+\exp((\ln \frac{1-\pi}{\pi})+\sum_i ( \frac{\mu_{i0}-\mu_{i1}}{\delta_i^2} X_i + \frac{\mu_{i1}^2-\mu_{i0}^2}{\delta_i^2} ))}\\
& = \frac{1}{1+\exp(w_0+\sum_{i=1}^{n}w_iX_i)}  \tag{3}
\end{align*}$$

其中，

$$\begin{align*}
w_0 & = \ln \frac{1-\pi}{\pi} + \sum_i \frac{\mu_{i1}^2-\mu_{i0}^2}{\delta_i^2}\\
w_i & = \frac{\mu_{i0}-\mu_{i1}}{\delta_i^2}
\end{align*}$$


[^1]: [GENERATIVE AND DISCRIMINATIVE CLASSIFIERS: NAIVE BAYES AND LOGISTIC REGRESSION](http://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf)