---
published: true
author: Charles
layout: post
title:  "Hadoop学习之HDFS"
date:   2016-04-09 14:28
categories: 大数据
---

#### 分布式文件系统

当数据集的大小超过一台独立物理计算机的存储能力时，就有必要对它进行分区(partition)并存储到若干台单独的计算机上。

管理网络中跨多台计算机存储的文件系统称为分布式文件系统(distributed filesystem)。该系统架构于网络之上，势必会引入网络编程的复杂性，因此分布式文件系统比普通磁盘文件系统更为复杂。例如，使文件系统能够容忍节点故障且不丢失任何数据，就是一个极大的挑战。

![此处输入图片的描述][1]

----------


#### HDFS设计目标
- 兼容廉价的硬件设备
- 流数据读写：一次写入、多次读写
- 大数据集
- 简单的文件模型
- 强大的跨平台兼容性


----------


#### HDFS缺点
HDFS特殊的设计，在实现上述优良特性的同时，也使得自身具有一些应用局限性，

- 不适合低延迟数据访问
- 无法高效存储大量小文件
- 不支持多用户写入及任意修改文件


----------


<p class="first">不适合低延迟数据访问</p>

如果要处理一些用户要求时间比较短的低延迟应用请求，则HDFS不适合。HDFS是为了处理大型数据集分析任务的，主要是为达到高的数据吞吐量而设计的，这就可能要求以高延迟作为代价。

**改进策略**：

- 对于那些有低延时要求的应用程序，HBase是一个更好的选择，它的口号就是goes real time。
- 使用缓存或多master设计可以降低client的数据请求压力，减小延时。
- 对HDFS系统内部改进，权衡大吞吐量与低延时。


----------


<p class="first">无法高效存储大量小文件</p>

因为Namenode把文件系统的元数据放置在内存中，所以文件系统所能容纳的文件数目是由Namenode的内存大小来决定。一般来说，每一个文件、 文件夹和Block需要占据150字节左右的空间，所以，如果你有100万个文件，每一个占据一个Block，你就至少需要300MB内存。当前来说，数 百万的文件还是可行的，当扩展到数十亿时，对于当前的硬件水平来说就没法实现了。

还有一个问题就 是，因为Map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的Map task，线程管理开销将会增加作业时间。举个例子，处理10000M的文件，若每个split为1M，那就会有10000个Map tasks，会有很大的线程开销；若每个split为100M，则只有100个Map tasks，每个Map task将会有更多的事情做，而线程的管理开销也将减小很多。

----------


<p class="first">不支持多用户写入及任意修改文件</p>

在HDFS的一个文件中只有一个写入者，而且写操作只能在文件末尾完成，即只能执行追加操作。目前HDFS还不支持多个用户对同一文件的写操作，以及在文件任意位置进行修改。


----------


分布式文件系统在物理结构上是由计算机集群中的多个节点构成的，这些节点分为两类，一类叫“主节点”(Master Node)或者也被称为“名称结点”(NameNode)，另一类叫“从节点”（Slave Node）或者也被称为“数据节点”(DataNode)


  [1]: http://7xjbdi.com1.z0.glb.clouddn.com/dfs.jpg?imageView2/2/w/300