---
published: true
author: Charles
layout: post
title:  "LDA中的数学知识"
date:   2016-03-18 15:30
categories: 机器学习 自然语言处理
---

之后准备花时间看看 Bayesian Statistics，现在的了解都太浅显。

 现在假设我们有这样几类概率：$P(\theta)$（先验分布）, $P(\theta\|x)$（后验分布）, $P(x)$, $P(x\|\theta)$ （似然函数） .

#### 贝叶斯定理
我们知道，很多时候，光靠 $P(x\|\theta)$ （即“似然”）是不够的，有时候还需要引入 $P(\theta)$ 这个先验概率。奥卡姆剃刀指的是 $P(\theta)$ 较大的模型有较大的优势，而最大似然则是说最符合观测数据的（即 $P(x\|\theta)$ 最大的）最有优势。

$$P(\theta|x) = \frac{P(x|\theta)P(\theta)}{P(x)} \propto P(x|\theta)P(\theta)$$

> 我们不妨再举一个简单的例子来说明这一精神：你随便找枚硬币，掷一下，观察一下结果。好，你观察到的结果要么是“正”，要么是“反”，不妨假设你观察到的是“正”。现在你要去根据这个观测数据推断这枚硬币掷出“正”的概率是多大。根据最大似然估计的精神，我们应该猜测这枚硬币掷出“正”的概率是 1 ，因为这个才是能最大化 $P(x\|\theta)$ 的那个猜测。然而每个人都会大摇其头——很显然，你随机摸出一枚硬币这枚硬币居然没有反面的概率是“不存在的”，我们对一枚随机硬币是否一枚有偏硬币，偏了多少，是有着一个**先验的认识**的，这个认识就是绝大多数硬币都是基本公平的，偏得越多的硬币越少见（可以用一个 **beta 分布** 来表达这一先验概率）。将这个先验正态分布 $p(\theta)$ （其中 $\theta$ 表示硬币掷出正面的比例，小写的 p 代表这是**概率密度函数**）结合到我们的问题中，我们便不是去最大化 $P(x\|\theta)$ ，而是去最大化 $P(x\|\theta)P(\theta)$ 。显然 $\theta = 1$ 是不行的，因为 $P(\theta=1)$ 为 0，导致整个乘积也为 0 。实际上，只要对这个式子求一个导数就可以得到最值点。[^1]

$$\mathrm{posterior} \propto \mathrm{prior} \times \mathrm{likelihood}$$

![此处输入图片的描述][1]


----------


#### 共轭先验分布
通过上面的分析，当我们知道先验概率 $p(\theta)$ 的时候，光用最大似然是不靠谱的，因为最大似然的猜测可能先验概率非常小。

那么，我们如何选取先验概率分布呢？

这里我们需要先了解下共轭先验公布。

> 在贝叶斯概率理论中，如果后验概率 $P(\theta\|x)$ 和先验概率 $p(\theta)$ 满足同样的分布，那么，先验分布和后验分布被叫做共轭分布，同时，**先验分布**称为**似然函数**的共轭先验分布。

**注意，共轭指的是先验分布和似然函数共轭。**

$$P(\theta|x) = \frac{P(x|\theta)P(\theta)}{\int P(x|\theta)P(\theta)d\theta} \tag{1}$$


http://wenku.baidu.com/view/a542dbf2770bf78a6529546a.html?st=1

  [1]: http://7xjbdi.com1.z0.glb.clouddn.com/Beta_distribution_pdf.svg.png
  


----------


  [^1]: [数学之美番外篇：平凡而又神奇的贝叶斯方法](http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/)
  [^2]: [共轭分布与共轭先验](http://blog.huanghao.me/?p=250)
